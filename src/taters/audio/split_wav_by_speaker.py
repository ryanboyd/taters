# taters/audio/speaker_split.py

from __future__ import annotations
import csv
import re
from pathlib import Path
from typing import Dict, List, Optional, Union

from pydub import AudioSegment


def _sanitize_speaker(name: str) -> str:
    name = (name or "SPEAKER_0").strip()
    name = name.replace(" ", "_")
    return re.sub(r"[^A-Za-z0-9_\-]+", "_", name)


def _clamp(v: int, lo: int, hi: int) -> int:
    return max(lo, min(v, hi))


def make_speaker_wavs_from_csv(
    source_wav: Union[str, Path],
    transcript_csv_path: Union[str, Path],
    output_dir: Union[str, Path, None] = None,   # <- renamed + optional
    *,
    overwrite_existing: bool = False,  # if the file already exists, let's not overwrite by default
    start_col: str = "start_time",
    end_col: str = "end_time",
    speaker_col: str = "speaker",
    time_unit: str = "ms",             # "ms" (default) or "s"
    silence_ms: int = 1000,            # silence length before/after each clip, in ms
    pre_silence_ms: Optional[int] = None,  # optional override for pre-silence
    post_silence_ms: Optional[int] = None, # optional override for post-silence
    sr: Optional[int] = 16000,         # resample; None = keep original rate
    mono: bool = True,                 # force mono output
    min_dur_ms: int = 50,              # skip ultra-short blips
) -> Dict[str, Path]:
    """
    Build one WAV per speaker by concatenating only that speaker's segments.
    Inserts silence before and after each segment (pre + clip + post).

    Output filenames are <source_stem>_<Friendly Speaker>.wav

    If `output_dir` is not provided, files are written to:
        <cwd>/audio_split/<source_stem>/
    """
    if time_unit not in ("ms", "s"):
        raise ValueError("time_unit must be 'ms' or 's'")

    # --- small helper for filename-friendly labels (keeps spaces) ---
    def _friendly_filename_label(name: str) -> str:
        s = (name or "").strip()
        s = s.replace("/", "_").replace("\\", "_")     # forbid path separators
        s = re.sub(r'[<>:"|?*]', "", s)               # trim problematic chars
        s = re.sub(r"\s+", " ", s)                    # collapse whitespace
        return s or "SPEAKER_0"

    # Resolve paths
    source_wav = Path(source_wav)
    transcript_csv_path = Path(transcript_csv_path)

    # Default predictable location if none provided
    out_dir = Path(output_dir) if output_dir is not None else (Path.cwd() / "audio_split" / source_wav.stem)
    out_dir.mkdir(parents=True, exist_ok=True)
    base_stem = source_wav.stem

    # Load audio once
    audio = AudioSegment.from_file(source_wav)
    if sr:
        audio = audio.set_frame_rate(sr)
    if mono:
        audio = audio.set_channels(1)

    # Factor to convert CSV time to milliseconds
    factor = 1000.0 if time_unit == "s" else 1.0
    audio_len_ms = len(audio)

    # Read CSV
    with transcript_csv_path.open(newline="", encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    # Collect segments by (sanitized) speaker key and remember friendly label
    segs_by_spk: Dict[str, List[tuple[int, int]]] = {}
    label_for_key: Dict[str, str] = {}

    for row in rows:
        try:
            start_raw = float(row[start_col])
            end_raw   = float(row[end_col])
            raw_spk   = str(row.get(speaker_col, "SPEAKER_0"))
        except Exception:
            continue

        start_ms = int(round(start_raw * factor))
        end_ms   = int(round(end_raw   * factor))
        if end_ms <= start_ms:
            continue
        if (end_ms - start_ms) < min_dur_ms:
            continue

        start_ms = _clamp(start_ms, 0, audio_len_ms)
        end_ms   = _clamp(end_ms,   0, audio_len_ms)
        if end_ms <= start_ms:
            continue

        spk_key = _sanitize_speaker(raw_spk)  # stable dict key
        segs_by_spk.setdefault(spk_key, []).append((start_ms, end_ms))
        label_for_key.setdefault(spk_key, _friendly_filename_label(raw_spk))

    # check to see if files already exist
    friendly = label_for_key.get(spk_key, spk_key)
    out_path = out_dir / f"{base_stem}_{friendly}.wav"

    if not overwrite_existing and Path(out_path).is_file():
        print("WAV file already exists; returning existing file.")
        return out_path

    # Sort by start time per speaker
    for spk_key in segs_by_spk:
        segs_by_spk[spk_key].sort(key=lambda t: (t[0], t[1]))

    # Silence chunks
    pre_ms  = silence_ms if pre_silence_ms  is None else pre_silence_ms
    post_ms = silence_ms if post_silence_ms is None else post_silence_ms
    pre_sil  = AudioSegment.silent(duration=max(0, pre_ms),  frame_rate=audio.frame_rate)
    post_sil = AudioSegment.silent(duration=max(0, post_ms), frame_rate=audio.frame_rate)
    if mono:
        pre_sil  = pre_sil.set_channels(1)
        post_sil = post_sil.set_channels(1)

    # Build one file per speaker; name = <source_stem>_<Friendly Label>.wav
    results: Dict[str, Path] = {}
    for spk_key, segs in segs_by_spk.items():
        out = AudioSegment.silent(duration=0, frame_rate=audio.frame_rate)
        if mono:
            out = out.set_channels(1)

        for (s, e) in segs:
            clip = audio[s:e]
            if len(clip) < min_dur_ms:
                continue
            out += pre_sil + clip + post_sil

        if len(out) == 0:
            continue

        out.export(out_path, format="wav", codec="pcm_s16le")
        results[friendly] = out_path

    return results


# Optional CLI for ad-hoc use
if __name__ == "__main__":
    import argparse
    p = argparse.ArgumentParser(description="Create per-speaker WAVs from a timestamped CSV transcript.")
    p.add_argument("--wav", required=True, help="Source audio (wav)")
    p.add_argument("--transcript_csv_path", required=True, help="Transcript CSV (start_time,end_time,speaker,text)")
    # optional output dir; default to ./audio_split/<source_stem>/
    p.add_argument("--output_dir", required=False, default=None,
                   help="Output dir for per-speaker wavs (default: ./audio_split/<source_stem>/)")
    p.add_argument("--unit", choices=["ms", "s"], default="ms", help="Timestamp unit in CSV (default: ms)")
    p.add_argument("--sr", type=int, default=16000, help="Output sample rate (Hz)")
    p.add_argument("--silence-ms", type=int, default=1000, help="Silence before/after each clip in ms")
    p.add_argument("--pre-silence-ms", type=int, default=None, help="Override pre-silence (ms)")
    p.add_argument("--post-silence-ms", type=int, default=None, help="Override post-silence (ms)")
    p.add_argument("--overwrite_existing", action="store_true", help="Overwrite existing output")
    args = p.parse_args()

    paths = make_speaker_wavs_from_csv(
        source_wav=args.wav,
        transcript_csv_path=args.transcript_csv_path,
        output_dir=args.output_dir,   # <- new name + optional
        time_unit=args.unit,
        sr=args.sr,
        silence_ms=args.silence_ms,
        pre_silence_ms=args.pre_silence_ms,
        post_silence_ms=args.post_silence_ms,
        overwrite_existing=args.overwrite_existing,
    )
    print("Wrote:", {k: str(v) for k, v in paths.items()})
